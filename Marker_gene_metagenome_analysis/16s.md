# Marker gene metagenomes analysis pipeline
The pipeline describes the method of taxonomy identification of bacterial/fungal/eukaryotic community based on the marker gene amplicons (16S/18S rRNA or ITS). To date, all the commands are executed on local machines with preinstalled [QIIME](http://qiime.org/) v.1 software. 

The pipeline was built for Illumina paired-end reads but could be used for other sequencing platform with some modifications.

## Joining paired-end reads
First, we need to run QIIME program and join the forward and reverse reads together:
```
$ qiime
$ join_paired_ends.py -f sample_L001_R1_001.fastq -r sample_L001_R2_001.fastq -o sample_joined
```
This command processes reads per sample. If you need multiple joining (joining all the samples with one command), run:
```
$ multiple_join_paired_ends.py -i input_folder_with_fastq_files -o output_folder
```
The result is a directory named `sample_joined`. Rename the file `fastqjoin.join.fastq` in it according to the sample name (e.g. `sample1.fastq`). The files `fastqjoin.un1.fastq` and `fastqjoin.un2.fastq` contain reads which failed to join and thus could be deleted. If their size is much larger than the size of `fastqjoin.join.fastq`, it indicates unsuccessful joining. Try to use another software in this case, e.g., [mothur](https://mothur.org/) (process described [below](##mothur)).


## Merging samples and quality filtering
```
$ split_libraries_fastq.py -i sample1.fastq,sample2.fastq --sample_ids sample1,sample2 -o qc/ -q 19 --barcode_type 'not-barcoded'
```
**NOTE:** For Ion Torrent reads add flags `--phred_offset 33` Ð¸ `--q 13`.

The output file `split_library_log.txt` contains number of reads which passed the filters. If stats looks unsatisfactory, loosen the `--p` parameter ("min number of consecutive high quality base calls to include a read (per single end read) as a fraction of the input read length [default: 0.75]" - qiime).

The output file `seqs.fna` contains all the filtered reads for all the samples.

QC of reads joined with mothur is described [below](##mothur).

## Chimera filtering
Looking for PCR chimeras in `seqs.fna`:
```
$ identify_chimeric_seqs.py -i qc/seqs.fna -m usearch61 -o chimeras/ -r 97_otus.fasta
```
**NOTE:** Files with reference marker gene sequences on the local machine:
- Bacterial *GreenGenes* 16S rRNA: 
`~/Desktop/amplicons/qiime_files/bacterial_files/gg_13_8_otus/rep_set/97_otus.fasta`

- Pro-/eukaryotic *SILVA* 16S/18S rRNA:
`~/Desktop/amplicons/qiime_files/silva_SSU_16S_18S/SILVA_128_QIIME_release/rep_set/rep_set_all/97/97_otus.fasta`

- Fungal ITS:
`/home/lab/Desktop/amplicons/qiime_files/fungal_files/97_otus.fasta`

The output file `chimeras/chimeras.txt` contains names of chimeric reads. Filter them out:
 ```
$ filter_fasta.py -f qc/seqs.fna -o qc/seq_chimeras_filtered.fna -s chimeras/chimeras.txt -n
```
The output file `seq_chimeras_filtered.fna` contains all the filtered reads without chimeras for all the samples.

## Samples demultiplexing
Samples should have approximately equal number of reads to be compared. For that, at first split the file `seq_chimeras_filtered.fna` to samples. To do that, we need a specially designed mapping file which looks like this:

| #SampleID | BarcodeSequence | LinkerPrimerSequence |
| :-------- |:----------------| :------------------- |
| sample1   | TCGTCGGCAGCGTCAGATGTGTATAAGAGACAGCCTACGGGNGGCWGCAG | sample1 |
| sample2   | TCGTCGGCAGCGTCAGATGTGTATAAGAGACAGCCTACGGGNGGCWGCAG | sample2 |
| sample3   | TCGTCGGCAGCGTCAGATGTGTATAAGAGACAGCCTACGGGNGGCWGCAG | sample3 |

This file contains 3 columns, where the first and the third ones are the sample names, and the second one is the Illumina technical sequence, the same for every sample and every marker gene (16S/18S/ITS). The file should be named `mapping.txt`.

Demultiplexing is performed using the proprietary script named `demultiplexing_by_sample.sh`:
```bash
$ mkdir reads/demultiplexed
$ bash
$ ./demultiplexing_by_sample.sh
```
As a result, `.fna` file for each sample will be created.

## Samples rarefying
Then, we need to pick the equal (minimal`*`) number of sequences randomly from each sample using the proprietary script named `rarefying.sh`:
```bash
$ mkdir reads/rarefied
$ ./rarefying.sh
```
`*` "minimal" in this case means that the number of reads to be kept after the rarefaction step is determined by the minimum number of reads in sample. For example, if we have 3 samples with 100, 200 and 300 reads, correspondingly, after this step the 1st sample stays the same, and for 2nd and 3rd samples 100 random reads will be kept.

To count the number of reads per sample, use:
```bash
$ grep -c '^>' reads/rarefied/*.fna
```

## OTU picking and stats counting
Merge rarefied reads and picking OTUs:
```
$ cat reads/rarefied/*.fna > merged.fna
$ pick_open_reference_otus.py -i merged.fna -o open_otu13_8 -m usearch61 -r 97_otus.fasta --min_otu_size 5 -p pick_open_reference_otus.properties
```
Count the number of reads with assigned OTU per sample:
```bash
$ biom summarize_table -i open_otu13_8/otu_table_mc5_w_tax_no_pynast_failures.biom -o open_otu13_8/reads_with_otu_per_sample.txt
```
Count the number of OTUs per sample:
```bash
$ biom summarize_table -i open_otu13_8/otu_table_mc5_w_tax_no_pynast_failures.biom --qualitative -o open_otu13_8/otu_per_sample.txt
```
Convert `.biom` file to readable format (just in case, such as for constructing the alpha rarefaction plot in [iNEXT online](https://chao.shinyapps.io/iNEXTOnline/)):
 ```bash
$ biom convert -i open_otu13_8/otu_table_mc5_w_tax_no_pynast_failures.biom -o open_otu13_8/otu_table_classic.txt --table-type "OTU table" --to-tsv --header-key=taxonomy
```

## Taxonomy tables
With absolute number of reads per taxon:
```
$ summarize_taxa.py -i open_otu13_8/otu_table_mc5_w_tax_no_pynast_failures.biom -m mapping.txt -a -L 2,3,4,5,6,7 -o reports/taxaSummary13_8/absolute_all
```
With relative taxonomy (the sum of values for all taxons per sample = 1):
```
$ summarize_taxa_through_plots.py -i open_otu13_8/otu_table_mc5_w_tax_no_pynast_failures.biom -m mapping.txt -o reports/taxaSummary13_8/plots -p summarize_taxa_through_plots.properties
```
As a result, the `.html` report with taxonomy barplots will be generated.
The tables could be used for plotting the heatmaps in R using the following code (`family.txt` is an input table with taxons (e.g. bacterial families) as rows and samples as columns):
```r
library('gplots')
family <- read.table('family.txt', row.names = 1, header = T)
family_m <- as.matrix(family)
pdf('heatmap_family.pdf', 10, 10)
heatmap.2(family_m, dendrogram='none', col=rich.colors(100), trace='none', cexCol=0.7, cexRow=0.7, margins=c(2, 19), Colv=NA, Rowv=NA, density.info='none', key.par=list(mar=c(8,0.5,6,0)), keysize=2.5)
dev.off()
```
## [Alpha diversity](http://www.metagenomics.wiki/pdf/definition/alpha-beta-diversity) indices
Get the indices (Chao1, Shannon, Simpson):
```
$ alpha_diversity.py -i open_otu13_8/otu_table_mc5_w_tax_no_pynast_failures.biom -m PD_whole_tree,chao1,observed_otus,shannon,simpson -t 97_otus.tree -o indices.txt
```
Rarefaction curves in `.html` report:
```
$ alpha_rarefaction.py -i open_otu13_8/otu_table_mc5_w_tax_no_pynast_failures.biom -m mapping.txt -p ~/Desktop/amplicons/qiime_files/alpha_rarefaction_bact.properties -t 97_otus.tree -o reports/diversity/alpha
```
## [Beta diversity](http://www.metagenomics.wiki/pdf/definition/alpha-beta-diversity) matrices
The final step is the analysis of beta diversity.
By the "weighted UniFrac" method:
```
$ beta_diversity.py -i open_otu13_8/otu_table_mc5_w_tax_no_pynast_failures.biom -m weighted_unifrac -t 97_otus.tree -o reports/diversity/beta/weightedUnifrac
```
By the "unweighted UniFrac" method:
```
$ beta_diversity.py -i open_otu13_8/otu_table_mc5_w_tax_no_pynast_failures.biom -m unweighted_unifrac -t 97_otus.tree -o reports/diversity/beta/unweightedUnifrac
```
The matrices could be used for constructing the PCoA plots in R using the following code:
```r
library(ape)
d <- read.table('weighted_unifrac_otu_table_mc5_w_tax_no_pynast_failures.txt', row.names=1, header=TRUE)
d <- as.matrix(d)
pc <- pcoa(d)
pdf("weighted_unifrac.pdf", 10, 10)
biplot(pc)
dev.off()
```
___

## Mothur (on the local machine)
### Joining reads:
```bash
$ ~/Desktop/soft/Mothur.linux_64/mothur/mothur
$ make.contigs(ffastq=sample1_L001_R1_001.fastq, rfastq=sample1_L001_R2_001.fastq)
$ quit()
```
In the output directory we need 2 files named `sample1_L001_R1_001.trim.contigs.fasta` and `sample1_L001_R1_001.trim.contigs.qual`. Convert them to `.fastq` format in QIIME:
```
$ qiime
$ convert_fastaqual_fastq.py -f sample1_L001_R1_001.trim.contigs.fasta -q sample1_L001_R1_001.trim.contigs.qual -o sample1
```
### Quality filtering:
```
$ split_libraries_fastq.py -i sample1.fastq,sample2.fastq --sample_ids sample1,sample2 -o qc/ --phred_offset 33  --barcode_type 'not-barcoded'
```
